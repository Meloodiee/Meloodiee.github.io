<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Melody</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-03-02T09:34:39.074Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Statistics</title>
    <link href="http://example.com/2021/03/02/Statistics/"/>
    <id>http://example.com/2021/03/02/Statistics/</id>
    <published>2021-03-02T09:33:06.000Z</published>
    <updated>2021-03-02T09:34:39.074Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Moment-Generating-Function"><a href="#Moment-Generating-Function" class="headerlink" title="Moment Generating Function"></a>Moment Generating Function</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>For a random variable $X$, if $E[e^{tx}]$ exists $\forall t \in(-h, h)$ for some $h&gt;0$, moment generating function $M(t)=E[e^{tx}]$</p><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><p>$X$ is a random variable with MGF $M_x(t)$  that exists $\forall t\in (-h,h)$ where $h&gt;0$, </p><ul><li> $Y=aX+b$ where $a,b\in \R$ and $a\ne 0$. Then, $M_y(t)=e^{bt}M_x(at)\forall t\in (-\frac{h}{\vert a\vert},\frac{h}{\vert a\vert})$</li><li>$M(0)=1$ ,and</li><li>$M^{(k)}(0)=E[x^k]$ where $M^{(k)}(t)=\frac{d^k}{dt^k}M(t)$  for $k=1,2,â€¦$</li><li><strong>Uniqueness:</strong> $M_x(t)=M_y(t)\forall t\in(-h, h)\iff X$ and $Y$ have the same distribution<h1 id="Multivariate-Random-Function"><a href="#Multivariate-Random-Function" class="headerlink" title="Multivariate Random Function"></a>Multivariate Random Function</h1><h2 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h2>Suppose $X$ and $Y$ are $r.v$ defined on the sample space $S$, </li><li><strong>Joint $CDF$ of $X$ and $Y$:</strong><br> $F(x,y)=P(\underbrace{X\le x,Y\le y}_{intersection\space of\space 2\space events})\forall(x,y)\in\R^2$</li><li><strong>Marginal $CDF$ of $X$ and $Y$:</strong> (holds for both discrete and continuous $r.v.$)<br> $F_1(x)/F_x(x)= \lim\limits_{y\rarr \infty}F(x,y)=P(X\le x),\forall x\in \R$<br> $F_2(y)/F_y(y)= \lim\limits_{x\rarr \infty}F(x,y)=P(Y\le y),\forall y\in \R$</li><li><strong>Marginal $PDF$ of $X$ and $Y$:</strong><ul><li>For discrete $r.v.$, <ul><li>$f_x(x)=P(X=x)=\displaystyle\sum_{all\space y}f(x,y)\forall x\in\R$</li><li>$f_y(y)=P(Y=y)=\displaystyle\sum_{all\space x}f(x,y)\forall y\in\R$</li></ul></li><li>For continuous $r.v.$,<ul><li>$f_x(x)=\int_{-\infty}^{\infty}f(x,y)dy\forall x\in\R$</li><li>$f_y(y)=\int_{-\infty}^{\infty}f(x,y)dx\forall y\in\R$<h2 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h2>Recall: Independent events are $P(A\cap B)=P(A)P(B)$<h5 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h5>$X$ ans $Y$ are $r.v.$ </li></ul></li></ul></li></ul><ol><li>If joint CDF $F(x,y)$, marginal CDFs $F_1(x)$ and $F_2(y)$, then $X$ and $Y$ are independent $\iff F(x,y)=F_1(x)F_2(y)\forall(x,y)\in\R^2$</li><li>If joint $pdf/pmf$ $f(x,y)$ and marginal $pdfs/pmfs$ $f_1(x)$ and $f_2(y)$ and $A_1={s:f_1(x)&gt;0}$, $A_2={y:f_2(y)&gt;0}$, $X$ and $Y$ are independent $\iff f(x,y)=f_1(x)f_2(y)\forall(x,y)\in(A_1\times A_2)$</li><li><strong>(factorization theorem of independence)</strong> If joint $pdf/pmf$ $f(x,y)$ and $A_1={s:f_1(x)&gt;0}$, $A_2={y:f_2(y)&gt;0}$, $X$ and $Y$ are independent $\iff\exist g(y)\ge 0$ such that $f(x,y)=g(x)h(y)\forall(x,y)\in(A_1\times A_2)$</li><li>If support $A$ is not rectangular, then $X$ and $Y$ must be dependent $i.e.$<br>  $\exist(x,y)s.t.x\in A_1,y\in A_2, but(x,y)\notin A \space i.e.$<br>  $f_1(x)&gt;0, f_2(y)&gt;0,f(x,y)=0$</li><li>if $X$ and $Y$ are independent random variables, then if $g,h$ are functions, then $g(x)$ and $h(y)$ are independent. (the reverse is false)<h2 id="Joint-Expectations"><a href="#Joint-Expectations" class="headerlink" title="Joint Expectations"></a>Joint Expectations</h2><h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h3></li></ol><ul><li>Suppose $X$ and $Y$ are bivariate discrete random variables and $h(x,y)$ is a real-valued function. Then, if $\displaystyle\sum_{(x,y)\in A}\vert h(x,y)\vert f(x,y)&lt;\infty$, then $E[h(x,y)]=\displaystyle\sum_{(x,y)\in A}h(x,y)f(x,y)$. Otherwise, $E[h(x,y)]$ DNE.</li><li>Suppose $X$ and $Y$ are bivariate continuous random variables and $h(x,y)$ is a real-valued function. Then, if $\int_{-\infty}^\infty\int_{-\infty}^\infty\vert h(x,y)\vert f(x,y)dxdy&lt;\infty,E[h(x,y)]=\int_{-\infty}^\infty\int_{-\infty}^\infty h(x,y) f(x,y)dxdy$. Otherwise, $E[h(x,y]$ DNE.<h3 id="Properties-1"><a href="#Properties-1" class="headerlink" title="Properties"></a>Properties</h3></li></ul><ol><li>Linearity</li><li>If $X$ and $Y$ are independent, then $\forall function\space g,h,E[g(X)h(Y)]=E[g(X)]E[h(Y)]$<h2 id="Covariance"><a href="#Covariance" class="headerlink" title="Covariance"></a>Covariance</h2>$Cov(X,Y)=E[(x-\mu_x)(y-\mu_y)],where\space\mu_x=E[X], \mu_y=E[Y]$<br>$Cov(X,Y)=0$, we say $X$ and $Y$ are <strong>uncorrelated</strong><h3 id="Properties-2"><a href="#Properties-2" class="headerlink" title="Properties"></a>Properties</h3></li><li>$Cov(X,Y)=E[XY]-E[X]E[Y]$</li><li> $X$ and $Y$ are independent $\implies Cov(X,Y)=0$ </li><li>$Cov(X,X)=Var(X)$</li><li>$Var(aX+bY)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)$</li><li>$Var[\sum_{i=1}^na_iX_i]=\sum_{i=1}^na_i^2Var(X_i)+\sum_{i\ne j}a_ia_jCov(X_i,X_j)$</li><li>$Cov(X+Y,Z)=Cov(X,Y)+Cov(Y,Z)$<h2 id="Correlation-Coefficient"><a href="#Correlation-Coefficient" class="headerlink" title="Correlation Coefficient"></a>Correlation Coefficient</h2>$$<br>\rho(x,y)=\frac{Cov(X,Y)}{\sqrt{Var(X)}\sqrt{Var(Y)}}<br>$$<br>$-1&lt;\rho&lt;1$ measures the strength of linear relationship between $X$ and $Y$<h1 id="Conditional-Distribution"><a href="#Conditional-Distribution" class="headerlink" title="Conditional Distribution"></a>Conditional Distribution</h1>$$<br>P(A\mid B)=\frac{P(A\cap B)}{P(B)} \space ,given \space P(B)&gt;0<br>$$<br>Suppose $X$ and $Y$ are bivariate random variables with joint pmf $f(x,y)$, then</li><li>conditional pmf/pdf of $X$ given $Y=y$ is<br>$$<br>f_1(x\mid y)=\frac{f(x,y)}{f_2(y)}\space,given\space f_2(y)&gt;0<br>$$</li><li>conditional pmf/pdf of $Y$ given $X=x$ is<br>$$<br>f_2(y\mid x)=\frac{f(x,y)}{f_1(x)}\space,given\space f_1(x)&gt;0<br>$$<h3 id="Properties-3"><a href="#Properties-3" class="headerlink" title="Properties"></a>Properties</h3>$X$ and $Y$ are random variables with marginal pdf/pmf $f_1(x)$ and $f_2(y)$ and marginal support $A_1$ and $A_2$</li><li>$X$ and $Y$ are independent $\iff f_1(x\mid y)=f_1(x)\forall x\in A_1 \lor f_2(y\mid x)=f_2(y)\forall y\in A_2$</li><li><strong>Product Rule:</strong> $f(x,y)=f_1(x\mid y)f_2(y)=f_2(y\mid x)f_1(x)$<h2 id="Conditional-Expectations"><a href="#Conditional-Expectations" class="headerlink" title="Conditional Expectations"></a>Conditional Expectations</h2>Function $g$, the conditional expectation of $g(Y)$ given $X=x$ is:<br>$$<br>E[g(Y)\mid X=x] = \begin{cases}<br>\displaystyle\sum_{all\space y}g(y)f_x(y\mid x) &amp;\text{if Y is discrete r.v.}  \<br>\int_{-\infty}^\infty g(y)f_2(y\mid x)dy &amp;\text{if Y is continuous r.v.}<br>\end{cases}, unless \sum_{all\space y}g(y)f_x(y\mid x)/\int_{-\infty}^\infty g(y)f_2(y\mid x)dy   \text{ does not converge,\ in which case} E[g(Y)\mid X=x] DNE<br>$$</li></ol><ul><li>$g(Y)=Y$, $E[Y\mid X=x]$ is called the <strong>conditional mean</strong></li><li>$g(y)=(y-E[Y\mid X=x])^2\implies \begin{aligned}Var[Y\mid X=x] &amp;= E\big[(Y-E[Y\mid X=x])^2\mid X=x\big]\&amp;=E[Y^2\mid X=x]-\big(E[y\mid X=x]\big)^2\end{aligned}$ is called <strong>conditional variance</strong><h3 id="Properties-4"><a href="#Properties-4" class="headerlink" title="Properties"></a>Properties</h3></li></ul><ol><li><strong>Independence:</strong> If $X$ and $Y$ are independent, $\forall g(\sdot) and\space h(\sdot),E[g(x)\mid Y=y] = E[g(x)]$ and $E[h(y)\mid X=x] = E[h(y)]$</li><li><strong>Substitution Rule:</strong> $E[h(X,Y)\mid X=x]=E[h(x,Y)\mid X=x]$</li><li><strong>Double Expectation:</strong> $E[G(Y)]=E\big[E[g(Y)\mid X]\big]$</li><li>$Var[Y]=E[\underbrace{Var(Y\mid X)}_{function\space h(x)=Var[Y\mid X = x]\space applied \space to \space r.v.\space X}]+Var[E[Y\vert X]]$<ol><li>$E[Var(Y\vert X)]$ : <ul><li>find $Var(Y\vert X)$ <ul><li> figure out the expression for $h(x)=Var(Y\vert X)$</li><li> substitute $X$ for big $x$ in that expression</li></ul></li><li>calculate $E[h(X)]$</li></ul></li><li>$Var[E[Y\vert X]]$:<ul><li>find $E[Y\vert X]$</li><li>calculate  $Var[\overbrace{E[Y\vert X]}^\text{~{h}(x)}]$<h1 id="Joint-Moment-Generating-Function-MGF"><a href="#Joint-Moment-Generating-Function-MGF" class="headerlink" title="Joint Moment Generating Function(MGF)"></a>Joint Moment Generating Function(MGF)</h1>$X$ and $Y$ are random variables. If $E[e^{t_1x+t_2y}]$ exists $\forall t_1\in(-h_1,h_1)$ and  $t_2\in(-h_2,h_2)$ for $h_1,h_2&gt;0$<br>Then, $M(t_1,t_2)=E[e^{t_1x+t_2y}]\forall t_1,t_2$such that $E[\sdot]$ exists is called the joint MGF<h2 id="Marginal-joint-MGF"><a href="#Marginal-joint-MGF" class="headerlink" title="Marginal joint MGF"></a>Marginal joint MGF</h2>Given $M(t_1,t_2)$</li></ul></li></ol></li></ol><ul><li>$M_x(t_1)=M(t_1,0)=E[e^{t_1x+0y}]=E[e^{t_1x}]$</li><li>$M_y(t_2)=M(0,t_2)=E[e^{0x+t_2y}]=E[e^{t_2y}]$<h3 id="Properties-5"><a href="#Properties-5" class="headerlink" title="Properties"></a>Properties</h3>$X$ and $Y$ are random variables with joint MGF $M(t_1,t_2)$. Then,<br>$X$ and $Y$ are independent $\iff M(t_1,t_2)=M_x(t_1)M_y(t_2)$<h1 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h1></li></ul><p>$$<br>(X_1,X_2,â€¦,X_k)\sim Multinomial(n;p_1,p_2,â€¦,p_k) \text{ is discrete random variable with joint pmf} \ f(x_1,x_2,â€¦,x_k)=\begin{cases}\frac{n!}{x_1!x_2!â€¦x_k!}p_1^{x_1}p_2^{x_2}â€¦p_k^{x_k} &amp;x_i=0,1,â€¦,n, i=1,2,â€¦,k,\sum_{i=1}^kx_1=n\0 &amp;o.w. \end{cases} \ for\space 0&lt;p_i&lt;1, \sum_{i=1}^kp_i=1<br>$$<br> Concrete example: k boxes randomly pick one of the k boxes, probability of picking the $i^{th}$ box being $p_i$. Repeat picking <em>n</em> times independently. $X_i$ is number of times box $i$ was picked, $i=1,2,â€¦,k$ </p><h3 id="Properties-6"><a href="#Properties-6" class="headerlink" title="Properties"></a>Properties</h3><p> $(X_1,X_2,â€¦,X_k)\sim Multinomial(n;p_1,p_2,â€¦,p_k)$</p><ol><li>Joint MGF $M(t_1,t_2,â€¦,t_k)=E[e^{t_1x_1+t_2x_2+â€¦+t_kx_k}]=(p_1e^{t_1}+â€¦+p_ke^{t_k})^n\forall (t_1,t_2,â€¦,t_k)\in \R^k$</li><li>$X_i\sim Binomial(n,p_i)for\space i=1,2,â€¦,k$</li><li>$T=X_i+X_j(i\ne j)\implies T\sim Binomial(n,p_i+p_j)$</li><li>$$E[X_i]=np_i\Var[X_i]=np_i(1-p_i)\Cov(X_i,X_j)=-np_ip_j(i\ne j)$$</li><li>$X_i\mid X_j=x_j\sim Bin(n-x_j,\frac{p_i}{1-p_j}),i\ne j$</li><li>$X_i\mid X_i+X_j=t\sim Bin(t,\frac{p_i}{p_i+p_j}),i\ne j$<h1 id="Bivariate-Normal-Distribution"><a href="#Bivariate-Normal-Distribution" class="headerlink" title="Bivariate Normal Distribution"></a>Bivariate Normal Distribution</h1>$$<br>\overrightarrow{x}=\begin{pmatrix}x_1\x_2\end{pmatrix}\sim BVN(\overrightarrow{\mu},\Sigma)\ where\space X_1\space and\space X_2 \text{ are continutous random variables with joint pdf }\f(x_1,x_2)=\frac{1}{2\pi |\Sigma|^{1/2}}exp{\frac{-(x-\mu)\Sigma^{-1}(x-\mu)^T}{2}},\ where\ x=\begin{pmatrix}x_1\x_2\end{pmatrix},\mu=\begin{pmatrix}\mu_1\ \mu_2\end{pmatrix},\Sigma=\begin{pmatrix}\sigma_1^2 &amp; \rho\sigma_1\sigma_2\ \rho\sigma_1\sigma_2 &amp; \sigma_2^2\end{pmatrix} is\ positive\ definite<br>$$<h3 id="Properties-7"><a href="#Properties-7" class="headerlink" title="Properties"></a>Properties</h3></li><li>$X_1,X_2$ has joint MGF$$M(t_1,t_2)=E[e^{t_1x_1+t_2x_2}]=exp{t^T\mu+\frac{1}{2}t^T\Sigma t}\forall t=\begin{pmatrix}t_1\t_2\end{pmatrix}\in\R^2$$</li><li>$M_{x_1}(t)=M(t,0)=exp{t_1\mu_1+\frac{1}{2}t_1^2\sigma_1^2}\to X_1\sim N(\mu,\sigma_1^2)\M_{x_2}(t)=M(0,t)=exp{t_2\mu_2+\frac{1}{2}t_2^2\sigma_2^2}\to X_2\sim N(\mu,\sigma_2^2)$</li><li>$Cov(X_1,X_2)=\rho\sigma_1\sigma_2$</li><li>$\rho=0\iff X_1\ and\ X_2$ are independent and correlated</li><li>$c=\begin{pmatrix}c_1\c_2\end{pmatrix}\ne 0,\ c^TX=c_1x_1+c_2x_2\sim N(\mu^Tc,c^T\Sigma c)$</li><li>Nonsingular matrix $A\in\R^{2\times 2},b\in\R^2,\ then\ AX+b\sim BVN(A\mu,A\Sigma A^T)$</li><li>$\Big((x-\mu)^T\Sigma^{-1}(x-\mu)\Big)\sim\chi^2$</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Moment-Generating-Function&quot;&gt;&lt;a href=&quot;#Moment-Generating-Function&quot; class=&quot;headerlink&quot; title=&quot;Moment Generating Function&quot;&gt;&lt;/a&gt;Moment G</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2021/02/22/hello-world/"/>
    <id>http://example.com/2021/02/22/hello-world/</id>
    <published>2021-02-22T08:18:46.210Z</published>
    <updated>2021-02-22T08:18:46.211Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
